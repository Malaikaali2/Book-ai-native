"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[2191],{6266(e,n,r){r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>_,frontMatter:()=>i,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"module-4-vla/nlp-robot-mapping","title":"Natural Language to Robot Action Mapping","description":"Learning Objectives","source":"@site/docs/module-4-vla/nlp-robot-mapping.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/nlp-robot-mapping","permalink":"/Book-ai-native/docs/module-4-vla/nlp-robot-mapping","draft":false,"unlisted":false,"editUrl":"https://github.com/Malaikaali2/Book-ai-native/tree/main/docs/module-4-vla/nlp-robot-mapping.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"Voice Command Interpretation System","permalink":"/Book-ai-native/docs/module-4-vla/voice-command-system"},"next":{"title":"Lab: VLA System Integration","permalink":"/Book-ai-native/docs/module-4-vla/lab-vla-integration"}}');var a=r(4848),o=r(8453);const i={sidebar_position:7},s="Natural Language to Robot Action Mapping",c={},l=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Language-to-Action Mapping",id:"introduction-to-language-to-action-mapping",level:2},{value:"The Translation Pipeline",id:"the-translation-pipeline",level:3},{value:"Semantic Parsing for Action Extraction",id:"semantic-parsing-for-action-extraction",level:2},{value:"Grammar-Based Semantic Parsing",id:"grammar-based-semantic-parsing",level:3},{value:"Neural Semantic Parsing",id:"neural-semantic-parsing",level:3},{value:"Context-Aware Action Mapping",id:"context-aware-action-mapping",level:2},{value:"Environmental Context Integration",id:"environmental-context-integration",level:3},{value:"Action Execution Planning",id:"action-execution-planning",level:2},{value:"Converting Mapped Actions to Executable Plans",id:"converting-mapped-actions-to-executable-plans",level:3},{value:"Ambiguity Resolution and Fallback Strategies",id:"ambiguity-resolution-and-fallback-strategies",level:2},{value:"Handling Ambiguous Language",id:"handling-ambiguous-language",level:3},{value:"Isaac Integration for Language-to-Action Mapping",id:"isaac-integration-for-language-to-action-mapping",level:2},{value:"ROS 2 Interface for Action Mapping",id:"ros-2-interface-for-action-mapping",level:3},{value:"Evaluation and Validation",id:"evaluation-and-validation",level:2},{value:"Language-to-Action Mapping Evaluation",id:"language-to-action-mapping-evaluation",level:3},{value:"Summary",id:"summary",level:2},{value:"References",id:"references",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"natural-language-to-robot-action-mapping",children:"Natural Language to Robot Action Mapping"})}),"\n",(0,a.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(n.p,{children:"By the end of this section, you will be able to:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Design systems that translate natural language commands into executable robot actions"}),"\n",(0,a.jsx)(n.li,{children:"Implement semantic parsing techniques that extract action-relevant information from language"}),"\n",(0,a.jsx)(n.li,{children:"Create robust mapping frameworks that handle ambiguous and complex language"}),"\n",(0,a.jsx)(n.li,{children:"Develop context-aware translation mechanisms that consider environmental constraints"}),"\n",(0,a.jsx)(n.li,{children:"Build validation and verification systems for language-to-action translation"}),"\n",(0,a.jsx)(n.li,{children:"Create fallback strategies for handling unmappable language commands"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"introduction-to-language-to-action-mapping",children:"Introduction to Language-to-Action Mapping"}),"\n",(0,a.jsx)(n.p,{children:"Natural language to robot action mapping is the critical process that transforms human linguistic expressions into executable robotic behaviors. This transformation involves multiple levels of interpretation, from understanding the literal meaning of words to inferring the intended action and grounding it in the robot's physical capabilities and environmental context."}),"\n",(0,a.jsx)(n.p,{children:"The complexity of this mapping stems from the fundamental differences between natural language and robotic action:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Ambiguity"}),": Natural language is inherently ambiguous, while robot actions require precise specifications"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Context Dependency"}),": Language meaning often depends on context, which must be properly interpreted"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Physical Constraints"}),": Robot capabilities and environmental constraints limit feasible actions"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Temporal Aspects"}),": Language may describe sequences, durations, and temporal relationships"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Spatial Reasoning"}),": Many commands involve spatial relationships and navigation"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"the-translation-pipeline",children:"The Translation Pipeline"}),"\n",(0,a.jsx)(n.p,{children:"The language-to-action mapping typically follows a pipeline approach:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"Natural Language \u2192 Semantic Parsing \u2192 Action Extraction \u2192 Parameter Grounding \u2192 Execution Planning \u2192 Robot Control\n"})}),"\n",(0,a.jsx)(n.p,{children:"Each stage refines the representation and adds more concrete details until the action can be executed by the robot's control systems."}),"\n",(0,a.jsx)(n.h2,{id:"semantic-parsing-for-action-extraction",children:"Semantic Parsing for Action Extraction"}),"\n",(0,a.jsx)(n.h3,{id:"grammar-based-semantic-parsing",children:"Grammar-Based Semantic Parsing"}),"\n",(0,a.jsx)(n.p,{children:"Grammar-based approaches use formal rules to extract action-relevant information:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import nltk\r\nfrom nltk import CFG\r\nfrom nltk.parse import ChartParser\r\nimport re\r\nfrom typing import Dict, List, Tuple\r\n\r\nclass GrammarBasedSemanticParser:\r\n    def __init__(self):\r\n        self.grammar = self.create_robot_command_grammar()\r\n        self.parser = ChartParser(self.grammar)\r\n        self.action_templates = self.load_action_templates()\r\n\r\n    def create_robot_command_grammar(self):\r\n        \"\"\"Create grammar for robot command language\"\"\"\r\n        grammar_str = \"\"\"\r\n            S -> COMMAND | SUBORDINATE_CLAUSE S\r\n            COMMAND -> ACTION OBJECT LOCATION\r\n                   | ACTION LOCATION\r\n                   | ACTION OBJECT\r\n                   | ACTION\r\n                   | NAVIGATE LOCATION\r\n                   | GRASP OBJECT\r\n                   | PLACE LOCATION\r\n            SUBORDINATE_CLAUSE -> 'then' | 'after' | 'and' | 'before'\r\n            ACTION -> 'go' | 'move' | 'navigate' | 'walk' | 'drive' | 'travel'\r\n                    | 'grasp' | 'pick' | 'grab' | 'take' | 'lift'\r\n                    | 'place' | 'put' | 'set' | 'drop'\r\n                    | 'look' | 'find' | 'search' | 'locate'\r\n                    | 'stop' | 'wait' | 'help'\r\n            OBJECT -> 'ball' | 'cup' | 'box' | 'book' | 'red_ball' | 'blue_cup'\r\n                    | 'the_ball' | 'a_cup' | 'it' | 'that' | 'this'\r\n            LOCATION -> 'kitchen' | 'living_room' | 'bedroom' | 'office'\r\n                      | 'table' | 'shelf' | 'counter' | 'couch'\r\n                      | 'left' | 'right' | 'front' | 'back'\r\n                      | 'near_ball' | 'by_cup'\r\n        \"\"\"\r\n        return CFG.fromstring(grammar_str)\r\n\r\n    def load_action_templates(self):\r\n        \"\"\"Load predefined action templates\"\"\"\r\n        return {\r\n            'navigate_to': {\r\n                'pattern': r'(?:go to|move to|navigate to|walk to|drive to)\\s+(?:the\\s+)?(\\w+)',\r\n                'action_type': 'navigation',\r\n                'parameters': ['target_location']\r\n            },\r\n            'grasp_object': {\r\n                'pattern': r'(?:grasp|pick up|take|grab)\\s+(?:the\\s+)?(\\w+)',\r\n                'action_type': 'manipulation',\r\n                'parameters': ['object_to_grasp']\r\n            },\r\n            'place_object': {\r\n                'pattern': r'(?:place|put|set)\\s+(?:the\\s+)?(\\w+)\\s+(?:on|at|in)\\s+(?:the\\s+)?(\\w+)',\r\n                'action_type': 'manipulation',\r\n                'parameters': ['object_to_place', 'target_location']\r\n            }\r\n        }\r\n\r\n    def parse_command(self, command: str) -> Dict:\r\n        \"\"\"Parse command using grammar-based approach\"\"\"\r\n        tokens = command.lower().split()\r\n\r\n        try:\r\n            # Parse using CFG\r\n            parses = list(self.parser.parse(tokens))\r\n            if parses:\r\n                return self.extract_action_from_parse(parses[0])\r\n        except:\r\n            # If grammar parsing fails, use regex patterns\r\n            return self.regex_parse_command(command)\r\n\r\n        return {'action_type': 'unknown', 'parameters': {}}\r\n\r\n    def extract_action_from_parse(self, parse_tree):\r\n        \"\"\"Extract action from parse tree\"\"\"\r\n        action_info = {'action_type': None, 'parameters': {}}\r\n\r\n        for subtree in parse_tree.subtrees():\r\n            if subtree.label() == 'ACTION':\r\n                action_info['action_type'] = str(subtree[0])\r\n            elif subtree.label() == 'OBJECT':\r\n                action_info['parameters']['object'] = str(subtree[0])\r\n            elif subtree.label() == 'LOCATION':\r\n                action_info['parameters']['location'] = str(subtree[0])\r\n\r\n        # Map to specific action type\r\n        action_info['action_type'] = self.map_to_specific_action(action_info['action_type'])\r\n        return action_info\r\n\r\n    def regex_parse_command(self, command: str) -> Dict:\r\n        \"\"\"Parse command using regex patterns as fallback\"\"\"\r\n        command_lower = command.lower()\r\n\r\n        for template_name, template in self.action_templates.items():\r\n            match = re.search(template['pattern'], command_lower)\r\n            if match:\r\n                params = {}\r\n                for i, param_name in enumerate(template['parameters']):\r\n                    if i < len(match.groups()):\r\n                        params[param_name] = match.group(i + 1)\r\n\r\n                return {\r\n                    'action_type': template['action_type'],\r\n                    'template': template_name,\r\n                    'parameters': params\r\n                }\r\n\r\n        return {'action_type': 'unknown', 'parameters': {}}\r\n\r\n    def map_to_specific_action(self, generic_action: str) -> str:\r\n        \"\"\"Map generic action to specific robot action\"\"\"\r\n        action_mapping = {\r\n            'go': 'navigate_to',\r\n            'move': 'navigate_to',\r\n            'navigate': 'navigate_to',\r\n            'walk': 'navigate_to',\r\n            'grasp': 'grasp_object',\r\n            'pick': 'grasp_object',\r\n            'grab': 'grasp_object',\r\n            'place': 'place_object',\r\n            'put': 'place_object',\r\n            'set': 'place_object'\r\n        }\r\n\r\n        return action_mapping.get(generic_action, generic_action)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"neural-semantic-parsing",children:"Neural Semantic Parsing"}),"\n",(0,a.jsx)(n.p,{children:"Neural approaches can handle more complex and ambiguous language:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nfrom transformers import AutoTokenizer, AutoModel\r\nimport numpy as np\r\n\r\nclass NeuralSemanticParser(nn.Module):\r\n    def __init__(self, vocab_size=30522, hidden_dim=768, action_dim=100):\r\n        super().__init__()\r\n\r\n        # Language model for encoding\r\n        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\r\n        self.language_model = AutoModel.from_pretrained('bert-base-uncased')\r\n\r\n        # Action classification head\r\n        self.action_classifier = nn.Linear(hidden_dim, action_dim)\r\n\r\n        # Parameter extraction heads\r\n        self.object_extractor = nn.Linear(hidden_dim, hidden_dim)\r\n        self.location_extractor = nn.Linear(hidden_dim, hidden_dim)\r\n        self.quantity_extractor = nn.Linear(hidden_dim, hidden_dim)\r\n\r\n        # Action embedding space\r\n        self.action_embeddings = nn.Embedding(action_dim, hidden_dim)\r\n\r\n        # Dropout for regularization\r\n        self.dropout = nn.Dropout(0.1)\r\n\r\n    def forward(self, input_text):\r\n        \"\"\"Parse input text into action representation\"\"\"\r\n        # Tokenize and encode\r\n        encoded = self.tokenizer(\r\n            input_text,\r\n            return_tensors='pt',\r\n            padding=True,\r\n            truncation=True,\r\n            max_length=128\r\n        )\r\n\r\n        # Get language model output\r\n        outputs = self.language_model(**encoded)\r\n        pooled_output = outputs.pooler_output  # [batch_size, hidden_dim]\r\n\r\n        # Apply dropout\r\n        pooled_output = self.dropout(pooled_output)\r\n\r\n        # Classify action\r\n        action_logits = self.action_classifier(pooled_output)\r\n        action_probs = F.softmax(action_logits, dim=-1)\r\n\r\n        # Extract parameters\r\n        object_features = self.object_extractor(pooled_output)\r\n        location_features = self.location_extractor(pooled_output)\r\n        quantity_features = self.quantity_extractor(pooled_output)\r\n\r\n        return {\r\n            'action_probs': action_probs,\r\n            'object_features': object_features,\r\n            'location_features': location_features,\r\n            'quantity_features': quantity_features,\r\n            'pooled_features': pooled_output\r\n        }\r\n\r\n    def extract_action_structure(self, input_text):\r\n        \"\"\"Extract structured action from text\"\"\"\r\n        outputs = self.forward(input_text)\r\n\r\n        # Get predicted action\r\n        predicted_action_id = torch.argmax(outputs['action_probs'], dim=-1).item()\r\n\r\n        # Get action name (would map to actual action names)\r\n        action_name = f\"action_{predicted_action_id}\"\r\n\r\n        # Extract parameters using attention over tokens\r\n        encoded = self.tokenizer(\r\n            input_text,\r\n            return_tensors='pt',\r\n            padding=True,\r\n            truncation=True,\r\n            max_length=128\r\n        )\r\n\r\n        token_embeddings = self.language_model(**encoded).last_hidden_state\r\n        attention_weights = torch.softmax(\r\n            torch.matmul(token_embeddings, outputs['object_features'].unsqueeze(-1)).squeeze(-1),\r\n            dim=-1\r\n        )\r\n\r\n        # Extract relevant tokens based on attention\r\n        relevant_tokens = torch.argmax(attention_weights, dim=-1)\r\n        extracted_params = self.extract_parameters_from_tokens(\r\n            input_text, relevant_tokens\r\n        )\r\n\r\n        return {\r\n            'action_type': action_name,\r\n            'parameters': extracted_params,\r\n            'confidence': torch.max(outputs['action_probs']).item()\r\n        }\r\n\r\n    def extract_parameters_from_tokens(self, text, attention_indices):\r\n        \"\"\"Extract parameters by analyzing attended tokens\"\"\"\r\n        tokens = self.tokenizer.tokenize(text)\r\n\r\n        # Simple extraction based on attention weights\r\n        # In practice, use more sophisticated parameter extraction\r\n        params = {}\r\n\r\n        # Look for object-related tokens\r\n        object_keywords = ['ball', 'cup', 'box', 'book', 'table', 'chair']\r\n        for token in tokens:\r\n            if token in object_keywords:\r\n                params['object'] = token\r\n                break\r\n\r\n        # Look for location-related tokens\r\n        location_keywords = ['kitchen', 'bedroom', 'office', 'table', 'shelf']\r\n        for token in tokens:\r\n            if token in location_keywords:\r\n                params['location'] = token\r\n                break\r\n\r\n        return params\r\n\r\nclass HybridSemanticParser:\r\n    def __init__(self):\r\n        self.grammar_parser = GrammarBasedSemanticParser()\r\n        self.neural_parser = NeuralSemanticParser()\r\n\r\n    def parse_command(self, command: str, context: Dict = None) -> Dict:\r\n        \"\"\"Parse command using hybrid approach\"\"\"\r\n        # Try grammar-based parsing first (for structured commands)\r\n        grammar_result = self.grammar_parser.parse_command(command)\r\n\r\n        if grammar_result['action_type'] != 'unknown':\r\n            return self.refine_with_context(grammar_result, context)\r\n\r\n        # Fall back to neural parsing for complex/ambiguous commands\r\n        neural_result = self.neural_parser.extract_action_structure(command)\r\n\r\n        # Convert neural result to expected format\r\n        refined_result = {\r\n            'action_type': neural_result['action_type'],\r\n            'parameters': neural_result['parameters'],\r\n            'confidence': neural_result.get('confidence', 0.5)\r\n        }\r\n\r\n        return self.refine_with_context(refined_result, context)\r\n\r\n    def refine_with_context(self, parsed_result: Dict, context: Dict) -> Dict:\r\n        \"\"\"Refine parsed result using contextual information\"\"\"\r\n        if not context:\r\n            return parsed_result\r\n\r\n        # Resolve pronouns using context\r\n        if 'object' in parsed_result['parameters']:\r\n            resolved_object = self.resolve_pronoun(\r\n                parsed_result['parameters']['object'], context\r\n            )\r\n            if resolved_object:\r\n                parsed_result['parameters']['object'] = resolved_object\r\n\r\n        # Ground locations in context\r\n        if 'location' in parsed_result['parameters']:\r\n            resolved_location = self.ground_location(\r\n                parsed_result['parameters']['location'], context\r\n            )\r\n            if resolved_location:\r\n                parsed_result['parameters']['resolved_location'] = resolved_location\r\n\r\n        # Validate against robot capabilities\r\n        if 'action_type' in parsed_result:\r\n            if not self.is_action_feasible(parsed_result['action_type'], context):\r\n                parsed_result['action_type'] = 'request_clarification'\r\n\r\n        return parsed_result\r\n\r\n    def resolve_pronoun(self, pronoun: str, context: Dict) -> str:\r\n        \"\"\"Resolve pronouns using context\"\"\"\r\n        pronoun_lower = pronoun.lower()\r\n\r\n        if pronoun_lower in ['it', 'that', 'this']:\r\n            # Get most recently mentioned object\r\n            recent_objects = context.get('recent_objects', [])\r\n            if recent_objects:\r\n                return recent_objects[-1]\r\n\r\n        return pronoun  # Return as-is if cannot resolve\r\n\r\n    def ground_location(self, location: str, context: Dict) -> Dict:\r\n        \"\"\"Ground location reference in context\"\"\"\r\n        named_locations = context.get('named_locations', {})\r\n\r\n        for name, pose in named_locations.items():\r\n            if location.lower() in name.lower():\r\n                return {\r\n                    'name': name,\r\n                    'pose': pose,\r\n                    'grounded': True\r\n                }\r\n\r\n        return {'name': location, 'grounded': False}\r\n\r\n    def is_action_feasible(self, action_type: str, context: Dict) -> bool:\r\n        \"\"\"Check if action is feasible given robot capabilities\"\"\"\r\n        robot_capabilities = context.get('robot_capabilities', [])\r\n\r\n        action_requirements = {\r\n            'navigation': ['navigation'],\r\n            'manipulation': ['manipulation'],\r\n            'perception': ['perception']\r\n        }\r\n\r\n        required_capability = action_requirements.get(action_type, [])\r\n        return any(cap in robot_capabilities for cap in required_capability)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"context-aware-action-mapping",children:"Context-Aware Action Mapping"}),"\n",(0,a.jsx)(n.h3,{id:"environmental-context-integration",children:"Environmental Context Integration"}),"\n",(0,a.jsx)(n.p,{children:"Effective language-to-action mapping must consider environmental context:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"class ContextAwareActionMapper:\r\n    def __init__(self):\r\n        self.spatial_reasoner = SpatialReasoner()\r\n        self.object_resolver = ObjectResolver()\r\n        self.constraint_checker = ConstraintChecker()\r\n\r\n    def map_with_context(self, parsed_command: Dict, environment_context: Dict) -> Dict:\r\n        \"\"\"Map command to action considering environmental context\"\"\"\r\n        action_mapping = {\r\n            'action_type': parsed_command['action_type'],\r\n            'original_parameters': parsed_command['parameters'],\r\n            'contextual_parameters': {},\r\n            'feasibility': True,\r\n            'confidence': parsed_command.get('confidence', 0.8)\r\n        }\r\n\r\n        # Ground spatial references\r\n        if 'location' in parsed_command['parameters']:\r\n            grounded_location = self.spatial_reasoner.ground_location(\r\n                parsed_command['parameters']['location'], environment_context\r\n            )\r\n            action_mapping['contextual_parameters']['target_pose'] = grounded_location\r\n\r\n        # Resolve object references\r\n        if 'object' in parsed_command['parameters']:\r\n            resolved_object = self.object_resolver.resolve_object(\r\n                parsed_command['parameters']['object'], environment_context\r\n            )\r\n            action_mapping['contextual_parameters']['target_object'] = resolved_object\r\n\r\n        # Check constraints\r\n        action_mapping['feasibility'] = self.constraint_checker.check_constraints(\r\n            action_mapping, environment_context\r\n        )\r\n\r\n        # Adjust parameters based on context\r\n        action_mapping = self.adjust_parameters_for_context(\r\n            action_mapping, environment_context\r\n        )\r\n\r\n        return action_mapping\r\n\r\n    def adjust_parameters_for_context(self, action_mapping: Dict, context: Dict) -> Dict:\r\n        \"\"\"Adjust action parameters based on context\"\"\"\r\n        action_type = action_mapping['action_type']\r\n        params = action_mapping['contextual_parameters']\r\n\r\n        if action_type == 'navigate_to':\r\n            # Adjust navigation parameters based on environment\r\n            target_pose = params.get('target_pose')\r\n            if target_pose:\r\n                # Consider obstacles, doorways, etc.\r\n                adjusted_params = self.adjust_navigation_params(target_pose, context)\r\n                params.update(adjusted_params)\r\n\r\n        elif action_type == 'grasp_object':\r\n            # Adjust grasp parameters based on object properties\r\n            target_object = params.get('target_object')\r\n            if target_object:\r\n                adjusted_params = self.adjust_grasp_params(target_object, context)\r\n                params.update(adjusted_params)\r\n\r\n        return action_mapping\r\n\r\n    def adjust_navigation_params(self, target_pose: Dict, context: Dict) -> Dict:\r\n        \"\"\"Adjust navigation parameters based on environment\"\"\"\r\n        adjusted = {}\r\n\r\n        # Consider doorways and narrow passages\r\n        if context.get('map'):\r\n            path = self.find_path_to_target(target_pose, context['map'])\r\n            adjusted['preferred_path'] = path\r\n\r\n        # Consider safety constraints\r\n        safety_margin = context.get('safety_settings', {}).get('margin', 0.1)\r\n        adjusted['safety_margin'] = safety_margin\r\n\r\n        # Consider speed constraints in crowded areas\r\n        if self.is_area_crowded(target_pose, context):\r\n            adjusted['max_speed'] = 0.2  # Slow down in crowded areas\r\n        else:\r\n            adjusted['max_speed'] = 0.5  # Normal speed\r\n\r\n        return adjusted\r\n\r\n    def adjust_grasp_params(self, target_object: Dict, context: Dict) -> Dict:\r\n        \"\"\"Adjust grasp parameters based on object properties\"\"\"\r\n        adjusted = {}\r\n\r\n        # Choose appropriate grasp based on object properties\r\n        obj_shape = target_object.get('shape', 'unknown')\r\n        obj_size = target_object.get('dimensions', {'width': 0.1, 'height': 0.1, 'depth': 0.1})\r\n        obj_weight = target_object.get('weight', 0.1)\r\n\r\n        grasp_type = self.select_grasp_type(obj_shape, obj_size, obj_weight)\r\n        adjusted['grasp_type'] = grasp_type\r\n\r\n        # Adjust gripper width\r\n        max_dimension = max(obj_size['width'], obj_size['depth'])\r\n        adjusted['gripper_width'] = max_dimension * 1.2  # Add safety margin\r\n\r\n        # Consider approach direction based on object orientation\r\n        obj_orientation = target_object.get('orientation', [0, 0, 0, 1])\r\n        approach_dir = self.compute_approach_direction(obj_orientation, obj_shape)\r\n        adjusted['approach_direction'] = approach_dir\r\n\r\n        return adjusted\r\n\r\n    def select_grasp_type(self, shape: str, dimensions: Dict, weight: float) -> str:\r\n        \"\"\"Select appropriate grasp type based on object properties\"\"\"\r\n        if shape == 'cylindrical':\r\n            return 'side_grasp'\r\n        elif dimensions['height'] < dimensions['width'] and dimensions['height'] < dimensions['depth']:\r\n            return 'top_grasp'\r\n        elif weight > 0.5:  # Heavy object\r\n            return 'power_grasp'\r\n        else:\r\n            return 'precision_grasp'\r\n\r\n    def compute_approach_direction(self, orientation: List[float], shape: str) -> List[float]:\r\n        \"\"\"Compute optimal approach direction based on object orientation\"\"\"\r\n        # Default approach direction (from above for top grasp)\r\n        if shape == 'cylindrical':\r\n            return [0, 0, -1]  # Approach from above\r\n        else:\r\n            return [0, -1, 0]  # Approach from front\r\n\r\n    def is_area_crowded(self, target_pose: Dict, context: Dict) -> bool:\r\n        \"\"\"Check if target area is crowded\"\"\"\r\n        # Implementation would check for nearby people/objects\r\n        # using occupancy grid or detection results\r\n        return False\r\n\r\n    def find_path_to_target(self, target_pose: Dict, map_data: Dict) -> List[Dict]:\r\n        \"\"\"Find path to target considering the map\"\"\"\r\n        # Implementation would use path planning algorithm\r\n        return [{'x': 0, 'y': 0}, target_pose]\r\n\r\nclass SpatialReasoner:\r\n    def __init__(self):\r\n        self.spatial_relations = {\r\n            'relative': ['left', 'right', 'front', 'back', 'near', 'far'],\r\n            'absolute': ['kitchen', 'living_room', 'bedroom', 'office']\r\n        }\r\n\r\n    def ground_location(self, location_ref: str, context: Dict) -> Dict:\r\n        \"\"\"Ground location reference in environmental context\"\"\"\r\n        location_lower = location_ref.lower()\r\n\r\n        # Check for absolute locations\r\n        absolute_locations = context.get('named_locations', {})\r\n        for name, pose in absolute_locations.items():\r\n            if location_lower in name.lower():\r\n                return {\r\n                    'type': 'absolute',\r\n                    'name': name,\r\n                    'pose': pose,\r\n                    'resolved': True\r\n                }\r\n\r\n        # Check for relative locations\r\n        if any(rel in location_lower for rel in self.spatial_relations['relative']):\r\n            return self.resolve_relative_location(location_ref, context)\r\n\r\n        # Default: return as reference\r\n        return {\r\n            'type': 'reference',\r\n            'name': location_ref,\r\n            'resolved': False\r\n        }\r\n\r\n    def resolve_relative_location(self, location_ref: str, context: Dict) -> Dict:\r\n        \"\"\"Resolve relative location reference\"\"\"\r\n        # Parse relative location (e.g., \"to the left of the table\")\r\n        words = location_ref.split()\r\n\r\n        # Find spatial relation and reference object\r\n        spatial_rel = None\r\n        ref_object = None\r\n\r\n        for i, word in enumerate(words):\r\n            if word in self.spatial_relations['relative']:\r\n                spatial_rel = word\r\n                # Look for object after the relation\r\n                if i + 2 < len(words):\r\n                    ref_object = ' '.join(words[i+2:])\r\n                break\r\n\r\n        if spatial_rel and ref_object:\r\n            # Find reference object in context\r\n            ref_obj = self.find_object_in_context(ref_object, context)\r\n            if ref_obj and 'pose' in ref_obj:\r\n                # Compute relative position\r\n                relative_pose = self.compute_relative_position(\r\n                    ref_obj['pose'], spatial_rel, context\r\n                )\r\n\r\n                return {\r\n                    'type': 'relative',\r\n                    'spatial_relation': spatial_rel,\r\n                    'reference_object': ref_obj,\r\n                    'pose': relative_pose,\r\n                    'resolved': True\r\n                }\r\n\r\n        return {\r\n            'type': 'relative',\r\n            'name': location_ref,\r\n            'resolved': False\r\n        }\r\n\r\n    def find_object_in_context(self, object_ref: str, context: Dict) -> Dict:\r\n        \"\"\"Find object in context\"\"\"\r\n        detected_objects = context.get('objects', [])\r\n\r\n        for obj in detected_objects:\r\n            obj_name = obj.get('type', '').lower()\r\n            if object_ref.lower() in obj_name:\r\n                return obj\r\n\r\n        return None\r\n\r\n    def compute_relative_position(self, ref_pose: List[float], relation: str, context: Dict) -> List[float]:\r\n        \"\"\"Compute position relative to reference object\"\"\"\r\n        ref_x, ref_y, ref_z = ref_pose[:3]\r\n\r\n        # Define relative offsets\r\n        offsets = {\r\n            'left': (-0.5, 0, 0),\r\n            'right': (0.5, 0, 0),\r\n            'front': (0, 0.5, 0),\r\n            'back': (0, -0.5, 0),\r\n            'near': (0, 0, 0),  # Same position\r\n            'far': (1, 1, 0)   # Further away\r\n        }\r\n\r\n        offset = offsets.get(relation, (0, 0, 0))\r\n        return [ref_x + offset[0], ref_y + offset[1], ref_z + offset[2]]\r\n\r\nclass ObjectResolver:\r\n    def __init__(self):\r\n        self.object_keywords = {\r\n            'graspable': ['ball', 'cup', 'box', 'book', 'bottle'],\r\n            'furniture': ['table', 'chair', 'shelf', 'couch', 'counter'],\r\n            'locations': ['kitchen', 'bedroom', 'office', 'living_room']\r\n        }\r\n\r\n    def resolve_object(self, object_ref: str, context: Dict) -> Dict:\r\n        \"\"\"Resolve object reference in context\"\"\"\r\n        object_lower = object_ref.lower()\r\n\r\n        # Check for pronouns\r\n        if object_lower in ['it', 'that', 'this']:\r\n            return self.resolve_pronoun(object_lower, context)\r\n\r\n        # Find in detected objects\r\n        detected_objects = context.get('objects', [])\r\n        for obj in detected_objects:\r\n            obj_type = obj.get('type', '').lower()\r\n            obj_color = obj.get('color', '').lower()\r\n\r\n            # Check if reference matches object\r\n            if (object_lower == obj_type or\r\n                object_lower == f\"{obj_color}_{obj_type}\" or\r\n                obj_type in object_lower):\r\n                return obj\r\n\r\n        # If not found, return reference with confidence\r\n        return {\r\n            'type': object_ref,\r\n            'found': False,\r\n            'confidence': 0.1\r\n        }\r\n\r\n    def resolve_pronoun(self, pronoun: str, context: Dict) -> Dict:\r\n        \"\"\"Resolve pronoun using context\"\"\"\r\n        if pronoun in ['it', 'that', 'this']:\r\n            # Get most recently mentioned object\r\n            recent_objects = context.get('recent_objects', [])\r\n            if recent_objects:\r\n                return recent_objects[-1]\r\n\r\n        return {'type': pronoun, 'found': False, 'confidence': 0.0}\n"})}),"\n",(0,a.jsx)(n.h2,{id:"action-execution-planning",children:"Action Execution Planning"}),"\n",(0,a.jsx)(n.h3,{id:"converting-mapped-actions-to-executable-plans",children:"Converting Mapped Actions to Executable Plans"}),"\n",(0,a.jsx)(n.p,{children:"Once actions are mapped from language, they need to be converted to executable plans:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"class ActionExecutionPlanner:\r\n    def __init__(self):\r\n        self.action_library = self.load_action_library()\r\n        self.motion_planner = MotionPlanner()\r\n        self.skill_executor = SkillExecutor()\r\n\r\n    def load_action_library(self):\r\n        \"\"\"Load action templates with execution specifications\"\"\"\r\n        return {\r\n            'navigate_to': {\r\n                'prerequisites': ['navigation_enabled', 'map_available'],\r\n                'execution_steps': [\r\n                    'plan_path',\r\n                    'execute_navigation',\r\n                    'verify_arrival'\r\n                ],\r\n                'parameters': ['target_pose', 'avoid_obstacles', 'max_speed'],\r\n                'timeout': 30.0\r\n            },\r\n            'grasp_object': {\r\n                'prerequisites': ['manipulation_enabled', 'object_reachable'],\r\n                'execution_steps': [\r\n                    'compute_approach_pose',\r\n                    'execute_approach',\r\n                    'execute_grasp',\r\n                    'verify_grasp'\r\n                ],\r\n                'parameters': ['object_pose', 'grasp_type', 'gripper_width'],\r\n                'timeout': 15.0\r\n            },\r\n            'place_object': {\r\n                'prerequisites': ['object_grasped'],\r\n                'execution_steps': [\r\n                    'compute_place_pose',\r\n                    'execute_place',\r\n                    'verify_placement',\r\n                    'release_object'\r\n                ],\r\n                'parameters': ['target_pose', 'orientation'],\r\n                'timeout': 10.0\r\n            },\r\n            'find_object': {\r\n                'prerequisites': ['perception_enabled'],\r\n                'execution_steps': [\r\n                    'scan_area',\r\n                    'detect_objects',\r\n                    'identify_target',\r\n                    'update_context'\r\n                ],\r\n                'parameters': ['object_type', 'search_area'],\r\n                'timeout': 20.0\r\n            }\r\n        }\r\n\r\n    def plan_execution(self, action_mapping: Dict) -> List[Dict]:\r\n        \"\"\"Plan execution steps for mapped action\"\"\"\r\n        action_type = action_mapping['action_type']\r\n\r\n        if action_type not in self.action_library:\r\n            raise ValueError(f\"Unknown action type: {action_type}\")\r\n\r\n        action_spec = self.action_library[action_type]\r\n        contextual_params = action_mapping.get('contextual_parameters', {})\r\n        original_params = action_mapping.get('original_parameters', {})\r\n\r\n        # Combine parameters\r\n        all_params = {**original_params, **contextual_params}\r\n\r\n        # Validate prerequisites\r\n        if not self.check_prerequisites(action_type, all_params):\r\n            raise ValueError(f\"Prerequisites not met for action: {action_type}\")\r\n\r\n        # Create execution plan\r\n        execution_plan = []\r\n        for step in action_spec['execution_steps']:\r\n            step_plan = self.create_step_plan(step, all_params, action_type)\r\n            execution_plan.append(step_plan)\r\n\r\n        return execution_plan\r\n\r\n    def check_prerequisites(self, action_type: str, parameters: Dict) -> bool:\r\n        \"\"\"Check if action prerequisites are met\"\"\"\r\n        action_spec = self.action_library.get(action_type, {})\r\n        prerequisites = action_spec.get('prerequisites', [])\r\n\r\n        # Check each prerequisite\r\n        for prereq in prerequisites:\r\n            if not self.evaluate_prerequisite(prereq, parameters):\r\n                return False\r\n\r\n        return True\r\n\r\n    def evaluate_prerequisite(self, prerequisite: str, parameters: Dict) -> bool:\r\n        \"\"\"Evaluate specific prerequisite\"\"\"\r\n        # This would interface with system state\r\n        # For now, return True for all prerequisites\r\n        return True\r\n\r\n    def create_step_plan(self, step: str, parameters: Dict, action_type: str) -> Dict:\r\n        \"\"\"Create plan for specific execution step\"\"\"\r\n        step_plan = {\r\n            'step': step,\r\n            'action_type': action_type,\r\n            'parameters': parameters,\r\n            'required_capabilities': self.get_required_capabilities(step, action_type),\r\n            'timeout': self.get_step_timeout(step, action_type)\r\n        }\r\n\r\n        # Add step-specific logic\r\n        if step == 'plan_path':\r\n            step_plan['command'] = 'plan_navigation_path'\r\n            step_plan['args'] = {\r\n                'start_pose': parameters.get('current_pose'),\r\n                'target_pose': parameters.get('target_pose'),\r\n                'avoid_obstacles': parameters.get('avoid_obstacles', True)\r\n            }\r\n        elif step == 'execute_navigation':\r\n            step_plan['command'] = 'execute_navigation'\r\n            step_plan['args'] = {\r\n                'target_pose': parameters.get('target_pose'),\r\n                'max_speed': parameters.get('max_speed', 0.5)\r\n            }\r\n        elif step == 'compute_approach_pose':\r\n            step_plan['command'] = 'compute_grasp_approach'\r\n            step_plan['args'] = {\r\n                'object_pose': parameters.get('object_pose'),\r\n                'approach_direction': parameters.get('approach_direction', [0, 0, 1])\r\n            }\r\n\r\n        return step_plan\r\n\r\n    def get_required_capabilities(self, step: str, action_type: str) -> List[str]:\r\n        \"\"\"Get required capabilities for execution step\"\"\"\r\n        capability_map = {\r\n            'navigate_to': {\r\n                'plan_path': ['navigation', 'path_planning'],\r\n                'execute_navigation': ['navigation', 'motion_control'],\r\n                'verify_arrival': ['localization']\r\n            },\r\n            'grasp_object': {\r\n                'compute_approach_pose': ['manipulation', 'kinematics'],\r\n                'execute_approach': ['manipulation', 'motion_control'],\r\n                'execute_grasp': ['manipulation', 'gripper_control'],\r\n                'verify_grasp': ['force_sensing', 'gripper_feedback']\r\n            }\r\n        }\r\n\r\n        action_caps = capability_map.get(action_type, {})\r\n        return action_caps.get(step, [])\r\n\r\n    def get_step_timeout(self, step: str, action_type: str) -> float:\r\n        \"\"\"Get timeout for execution step\"\"\"\r\n        timeout_map = {\r\n            'navigate_to': {\r\n                'plan_path': 5.0,\r\n                'execute_navigation': 30.0,\r\n                'verify_arrival': 2.0\r\n            },\r\n            'grasp_object': {\r\n                'compute_approach_pose': 1.0,\r\n                'execute_approach': 10.0,\r\n                'execute_grasp': 5.0,\r\n                'verify_grasp': 2.0\r\n            }\r\n        }\r\n\r\n        action_timeouts = timeout_map.get(action_type, {})\r\n        return action_timeouts.get(step, 5.0)\r\n\r\nclass MotionPlanner:\r\n    def __init__(self):\r\n        self.path_planner = PathPlanner()\r\n        self.trajectory_generator = TrajectoryGenerator()\r\n\r\n    def plan_navigation_path(self, start_pose: List[float], target_pose: List[float],\r\n                           map_data: Dict, avoid_obstacles: bool = True) -> List[List[float]]:\r\n        \"\"\"Plan navigation path from start to target\"\"\"\r\n        # This would implement actual path planning\r\n        # For now, return a simple straight-line path\r\n        path = self.interpolate_path(start_pose, target_pose)\r\n        return path\r\n\r\n    def plan_manipulation_trajectory(self, start_pose: List[float], target_pose: List[float],\r\n                                   constraints: Dict = None) -> List[Dict]:\r\n        \"\"\"Plan manipulation trajectory\"\"\"\r\n        # This would implement Cartesian or joint-space trajectory planning\r\n        trajectory = self.generate_trajectory(start_pose, target_pose, constraints)\r\n        return trajectory\r\n\r\n    def interpolate_path(self, start: List[float], end: List[float],\r\n                        num_points: int = 10) -> List[List[float]]:\r\n        \"\"\"Interpolate path between start and end poses\"\"\"\r\n        path = []\r\n        for i in range(num_points + 1):\r\n            t = i / num_points\r\n            point = [\r\n                start[0] + t * (end[0] - start[0]),\r\n                start[1] + t * (end[1] - start[1]),\r\n                start[2] + t * (end[2] - start[2])\r\n            ]\r\n            path.append(point)\r\n        return path\r\n\r\n    def generate_trajectory(self, start_pose: List[float], target_pose: List[float],\r\n                          constraints: Dict) -> List[Dict]:\r\n        \"\"\"Generate trajectory with constraints\"\"\"\r\n        # Implementation would generate smooth trajectory\r\n        # considering velocity, acceleration, and joint limits\r\n        pass\r\n\r\nclass SkillExecutor:\r\n    def __init__(self):\r\n        self.skills = self.load_skills()\r\n\r\n    def load_skills(self):\r\n        \"\"\"Load available robot skills\"\"\"\r\n        return {\r\n            'navigate': NavigateSkill(),\r\n            'grasp': GraspSkill(),\r\n            'place': PlaceSkill(),\r\n            'look_at': LookAtSkill(),\r\n            'find_object': FindObjectSkill()\r\n        }\r\n\r\n    def execute_skill(self, skill_name: str, parameters: Dict) -> Dict:\r\n        \"\"\"Execute robot skill with given parameters\"\"\"\r\n        if skill_name not in self.skills:\r\n            return {\r\n                'success': False,\r\n                'error': f'Skill {skill_name} not available',\r\n                'result': None\r\n            }\r\n\r\n        skill = self.skills[skill_name]\r\n        return skill.execute(parameters)\r\n\r\nclass BaseSkill:\r\n    def __init__(self, name: str):\r\n        self.name = name\r\n\r\n    def execute(self, parameters: Dict) -> Dict:\r\n        \"\"\"Execute the skill with given parameters\"\"\"\r\n        raise NotImplementedError\r\n\r\n    def validate_parameters(self, parameters: Dict) -> bool:\r\n        \"\"\"Validate skill parameters\"\"\"\r\n        return True\r\n\r\nclass NavigateSkill(BaseSkill):\r\n    def __init__(self):\r\n        super().__init__(\"navigate\")\r\n\r\n    def execute(self, parameters: Dict) -> Dict:\r\n        \"\"\"Execute navigation skill\"\"\"\r\n        try:\r\n            target_pose = parameters['target_pose']\r\n            max_speed = parameters.get('max_speed', 0.5)\r\n            avoid_obstacles = parameters.get('avoid_obstacles', True)\r\n\r\n            # Execute navigation\r\n            result = self.perform_navigation(target_pose, max_speed, avoid_obstacles)\r\n\r\n            return {\r\n                'success': result['reached_target'],\r\n                'final_pose': result.get('final_pose'),\r\n                'execution_time': result.get('time', 0.0),\r\n                'path_length': result.get('path_length', 0.0),\r\n                'result': result\r\n            }\r\n        except Exception as e:\r\n            return {\r\n                'success': False,\r\n                'error': str(e),\r\n                'result': None\r\n            }\r\n\r\n    def perform_navigation(self, target_pose: List[float], max_speed: float,\r\n                         avoid_obstacles: bool) -> Dict:\r\n        \"\"\"Perform actual navigation\"\"\"\r\n        # Implementation would interface with navigation stack\r\n        # For now, simulate navigation\r\n        import time\r\n        start_time = time.time()\r\n\r\n        # Simulate navigation\r\n        time.sleep(0.1)  # Simulate execution time\r\n\r\n        return {\r\n            'reached_target': True,\r\n            'final_pose': target_pose,\r\n            'time': time.time() - start_time,\r\n            'path_length': 1.0  # Simulated path length\r\n        }\n"})}),"\n",(0,a.jsx)(n.h2,{id:"ambiguity-resolution-and-fallback-strategies",children:"Ambiguity Resolution and Fallback Strategies"}),"\n",(0,a.jsx)(n.h3,{id:"handling-ambiguous-language",children:"Handling Ambiguous Language"}),"\n",(0,a.jsx)(n.p,{children:"Language-to-action mapping must handle ambiguous commands gracefully:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"class AmbiguityResolver:\r\n    def __init__(self):\r\n        self.ambiguity_patterns = self.load_ambiguity_patterns()\r\n        self.disambiguation_strategies = self.load_disambiguation_strategies()\r\n\r\n    def load_ambiguity_patterns(self):\r\n        \"\"\"Load patterns that indicate ambiguity\"\"\"\r\n        return {\r\n            'object_ambiguity': [\r\n                r'the \\w+',  # \"the ball\" when multiple balls exist\r\n                r'it',       # Pronoun without clear reference\r\n                r'that'      # Demonstrative without clear reference\r\n            ],\r\n            'spatial_ambiguity': [\r\n                r'over there',    # Vague location\r\n                r'somewhere',     # Indefinite location\r\n                r'around here'    # General area reference\r\n            ],\r\n            'action_ambiguity': [\r\n                r'do something',  # Vague action request\r\n                r'move it',      # Action without clear target\r\n                r'handle that'   # Generic handling instruction\r\n            ]\r\n        }\r\n\r\n    def load_disambiguation_strategies(self):\r\n        \"\"\"Load strategies for resolving ambiguities\"\"\"\r\n        return {\r\n            'object_ambiguity': [\r\n                'ask_for_clarification',\r\n                'use_most_recent_object',\r\n                'use_closest_object',\r\n                'use_largest_object'\r\n            ],\r\n            'spatial_ambiguity': [\r\n                'ask_for_clarification',\r\n                'use_robot_location',\r\n                'use_pointing_gesture',\r\n                'use_visual_attention'\r\n            ],\r\n            'action_ambiguity': [\r\n                'ask_for_clarification',\r\n                'use_default_action',\r\n                'request_specific_action'\r\n            ]\r\n        }\r\n\r\n    def detect_ambiguity(self, command: str, context: Dict) -> Dict:\r\n        \"\"\"Detect ambiguities in command\"\"\"\r\n        ambiguity_info = {\r\n            'types': [],\r\n            'detected': False,\r\n            'strategies': []\r\n        }\r\n\r\n        command_lower = command.lower()\r\n\r\n        # Check for object ambiguity\r\n        if self.check_pattern_match(command_lower, self.ambiguity_patterns['object_ambiguity']):\r\n            ambiguity_info['types'].append('object_ambiguity')\r\n            ambiguity_info['detected'] = True\r\n            ambiguity_info['strategies'].extend(\r\n                self.disambiguation_strategies['object_ambiguity']\r\n            )\r\n\r\n        # Check for spatial ambiguity\r\n        if self.check_pattern_match(command_lower, self.ambiguity_patterns['spatial_ambiguity']):\r\n            ambiguity_info['types'].append('spatial_ambiguity')\r\n            ambiguity_info['detected'] = True\r\n            ambiguity_info['strategies'].extend(\r\n                self.disambiguation_strategies['spatial_ambiguity']\r\n            )\r\n\r\n        # Check for action ambiguity\r\n        if self.check_pattern_match(command_lower, self.ambiguity_patterns['action_ambiguity']):\r\n            ambiguity_info['types'].append('action_ambiguity')\r\n            ambiguity_info['detected'] = True\r\n            ambiguity_info['strategies'].extend(\r\n                self.disambiguation_strategies['action_ambiguity']\r\n            )\r\n\r\n        return ambiguity_info\r\n\r\n    def check_pattern_match(self, text: str, patterns: List[str]) -> bool:\r\n        \"\"\"Check if text matches any of the given patterns\"\"\"\r\n        for pattern in patterns:\r\n            if re.search(pattern, text):\r\n                return True\r\n        return False\r\n\r\n    def resolve_ambiguity(self, command: str, ambiguity_info: Dict, context: Dict) -> Dict:\r\n        \"\"\"Resolve detected ambiguities\"\"\"\r\n        if not ambiguity_info['detected']:\r\n            return {'command': command, 'resolved': True, 'clarification_needed': False}\r\n\r\n        # For each ambiguity type, apply resolution strategy\r\n        resolved_command = command\r\n        clarification_needed = False\r\n\r\n        for ambiguity_type in ambiguity_info['types']:\r\n            if ambiguity_type == 'object_ambiguity':\r\n                resolution = self.resolve_object_ambiguity(command, context)\r\n                if resolution['clarification_needed']:\r\n                    clarification_needed = True\r\n                else:\r\n                    resolved_command = resolution['command']\r\n            elif ambiguity_type == 'spatial_ambiguity':\r\n                resolution = self.resolve_spatial_ambiguity(command, context)\r\n                if resolution['clarification_needed']:\r\n                    clarification_needed = True\r\n                else:\r\n                    resolved_command = resolution['command']\r\n            elif ambiguity_type == 'action_ambiguity':\r\n                resolution = self.resolve_action_ambiguity(command, context)\r\n                if resolution['clarification_needed']:\r\n                    clarification_needed = True\r\n                else:\r\n                    resolved_command = resolution['command']\r\n\r\n        return {\r\n            'command': resolved_command,\r\n            'resolved': True,\r\n            'clarification_needed': clarification_needed,\r\n            'original_ambiguities': ambiguity_info['types']\r\n        }\r\n\r\n    def resolve_object_ambiguity(self, command: str, context: Dict) -> Dict:\r\n        \"\"\"Resolve object reference ambiguity\"\"\"\r\n        detected_objects = context.get('objects', [])\r\n\r\n        if len(detected_objects) == 0:\r\n            # No objects detected, need clarification\r\n            return {\r\n                'command': command,\r\n                'clarification_needed': True,\r\n                'request': 'I cannot see any objects. Could you please point to or describe the object you mean?'\r\n            }\r\n\r\n        elif len(detected_objects) == 1:\r\n            # Only one object, assume this is the intended one\r\n            target_object = detected_objects[0]\r\n            resolved_command = self.substitute_object_reference(command, target_object)\r\n            return {\r\n                'command': resolved_command,\r\n                'clarification_needed': False\r\n            }\r\n\r\n        else:\r\n            # Multiple objects, need to disambiguate\r\n            # Look for additional context clues in the command\r\n            specific_clues = self.find_specific_clues(command, detected_objects)\r\n\r\n            if specific_clues:\r\n                # Found specific clues, use them to identify object\r\n                target_object = specific_clues[0]  # Use first match\r\n                resolved_command = self.substitute_object_reference(command, target_object)\r\n                return {\r\n                    'command': resolved_command,\r\n                    'clarification_needed': False\r\n                }\r\n            else:\r\n                # Cannot disambiguate automatically, ask for clarification\r\n                object_names = [obj.get('type', 'object') for obj in detected_objects[:3]]\r\n                object_list = ', '.join(object_names)\r\n                return {\r\n                    'command': command,\r\n                    'clarification_needed': True,\r\n                    'request': f'I see multiple objects: {object_list}. Could you specify which one you mean?'\r\n                }\r\n\r\n    def find_specific_clues(self, command: str, objects: List[Dict]) -> List[Dict]:\r\n        \"\"\"Find objects that match specific clues in the command\"\"\"\r\n        command_lower = command.lower()\r\n        matching_objects = []\r\n\r\n        for obj in objects:\r\n            obj_type = obj.get('type', '').lower()\r\n            obj_color = obj.get('color', '').lower()\r\n            obj_size = obj.get('size', '').lower()\r\n            obj_location = obj.get('location', '').lower()\r\n\r\n            # Check if object properties match command clues\r\n            if (obj_type in command_lower or\r\n                obj_color in command_lower or\r\n                obj_size in command_lower or\r\n                obj_location in command_lower):\r\n                matching_objects.append(obj)\r\n\r\n        return matching_objects\r\n\r\n    def substitute_object_reference(self, command: str, target_object: Dict) -> str:\r\n        \"\"\"Substitute ambiguous object reference with specific object\"\"\"\r\n        # This is a simplified substitution\r\n        # In practice, use more sophisticated NLP\r\n        obj_type = target_object.get('type', 'object')\r\n\r\n        # Replace ambiguous references with specific object\r\n        command = re.sub(r'\\bthe \\w+\\b', f\"the {obj_type}\", command)\r\n        command = re.sub(r'\\bit\\b|\\bthat\\b|\\bthis\\b', f\"the {obj_type}\", command)\r\n\r\n        return command\r\n\r\n    def resolve_spatial_ambiguity(self, command: str, context: Dict) -> Dict:\r\n        \"\"\"Resolve spatial reference ambiguity\"\"\"\r\n        # Check for vague spatial references\r\n        if 'over there' in command.lower() or 'somewhere' in command.lower():\r\n            # Use pointing gesture or visual attention if available\r\n            pointing_direction = context.get('pointing_direction')\r\n            if pointing_direction:\r\n                # Convert pointing to specific location\r\n                pointed_location = self.direction_to_location(pointing_direction, context)\r\n                resolved_command = self.substitute_spatial_reference(command, pointed_location)\r\n                return {\r\n                    'command': resolved_command,\r\n                    'clarification_needed': False\r\n                }\r\n            else:\r\n                # Ask for clarification\r\n                return {\r\n                    'command': command,\r\n                    'clarification_needed': True,\r\n                    'request': 'Could you please point to or be more specific about where you mean?'\r\n                }\r\n\r\n        return {\r\n            'command': command,\r\n            'clarification_needed': False\r\n        }\r\n\r\n    def direction_to_location(self, direction: List[float], context: Dict) -> str:\r\n        \"\"\"Convert pointing direction to location name\"\"\"\r\n        # This would use spatial reasoning to identify location\r\n        # For now, return a generic location\r\n        return \"the area you're pointing to\"\r\n\r\n    def substitute_spatial_reference(self, command: str, location: str) -> str:\r\n        \"\"\"Substitute spatial reference with specific location\"\"\"\r\n        command = re.sub(r'over there|somewhere|around here', location, command, flags=re.IGNORECASE)\r\n        return command\r\n\r\n    def resolve_action_ambiguity(self, command: str, context: Dict) -> Dict:\r\n        \"\"\"Resolve action ambiguity\"\"\"\r\n        # For vague action requests, ask for clarification\r\n        return {\r\n            'command': command,\r\n            'clarification_needed': True,\r\n            'request': f\"I'm not sure what you mean by '{command}'. Could you please be more specific about what you'd like me to do?\"\r\n        }\r\n\r\nclass FallbackManager:\r\n    def __init__(self):\r\n        self.fallback_strategies = [\r\n            'ask_for_clarification',\r\n            'request_repetition',\r\n            'suggest_alternative',\r\n            'execute_safe_default',\r\n            'handoff_to_human'\r\n        ]\r\n\r\n    def handle_unmappable_command(self, command: str, context: Dict) -> Dict:\r\n        \"\"\"Handle commands that cannot be mapped to actions\"\"\"\r\n        # Determine appropriate fallback strategy\r\n        strategy = self.select_fallback_strategy(command, context)\r\n\r\n        if strategy == 'ask_for_clarification':\r\n            return self.ask_for_clarification(command, context)\r\n        elif strategy == 'request_repetition':\r\n            return self.request_repetition(command)\r\n        elif strategy == 'suggest_alternative':\r\n            return self.suggest_alternative_actions(command, context)\r\n        elif strategy == 'execute_safe_default':\r\n            return self.execute_safe_default_action(command, context)\r\n        elif strategy == 'handoff_to_human':\r\n            return self.handoff_to_human(command, context)\r\n\r\n    def select_fallback_strategy(self, command: str, context: Dict) -> str:\r\n        \"\"\"Select appropriate fallback strategy\"\"\"\r\n        command_lower = command.lower()\r\n\r\n        # Check for specific conditions that suggest certain strategies\r\n        if any(word in command_lower for word in ['help', 'please', 'can you']):\r\n            return 'ask_for_clarification'\r\n        elif any(word in command_lower for word in ['stop', 'wait', 'pause']):\r\n            return 'execute_safe_default'\r\n        elif len(command.split()) < 3:\r\n            return 'request_repetition'\r\n        else:\r\n            return 'ask_for_clarification'\r\n\r\n    def ask_for_clarification(self, command: str, context: Dict) -> Dict:\r\n        \"\"\"Ask user for clarification\"\"\"\r\n        return {\r\n            'action_type': 'request_clarification',\r\n            'message': f\"I didn't understand '{command}'. Could you please rephrase or be more specific?\",\r\n            'options': self.generate_possible_interpretations(command, context),\r\n            'strategy': 'ask_for_clarification'\r\n        }\r\n\r\n    def generate_possible_interpretations(self, command: str, context: Dict) -> List[str]:\r\n        \"\"\"Generate possible interpretations of ambiguous command\"\"\"\r\n        # This would use NLP to generate possible interpretations\r\n        # For now, return some generic options\r\n        return [\r\n            f\"Did you mean: go somewhere?\",\r\n            f\"Did you mean: find something?\",\r\n            f\"Did you mean: do a specific action?\"\r\n        ]\r\n\r\n    def request_repetition(self, command: str) -> Dict:\r\n        \"\"\"Request user to repeat command\"\"\"\r\n        return {\r\n            'action_type': 'request_repetition',\r\n            'message': f\"I couldn't process '{command}'. Could you please repeat that?\",\r\n            'strategy': 'request_repetition'\r\n        }\r\n\r\n    def suggest_alternative_actions(self, command: str, context: Dict) -> Dict:\r\n        \"\"\"Suggest alternative actions based on partial understanding\"\"\"\r\n        available_actions = context.get('available_actions', [\r\n            'navigate to location',\r\n            'grasp object',\r\n            'place object',\r\n            'find object',\r\n            'stop movement'\r\n        ])\r\n\r\n        return {\r\n            'action_type': 'suggest_alternative',\r\n            'message': f\"I'm not sure how to '{command}'. Here are things I can do: {', '.join(available_actions[:3])}\",\r\n            'suggestions': available_actions,\r\n            'strategy': 'suggest_alternative'\r\n        }\r\n\r\n    def execute_safe_default_action(self, command: str, context: Dict) -> Dict:\r\n        \"\"\"Execute a safe default action\"\"\"\r\n        return {\r\n            'action_type': 'safe_default',\r\n            'executed_action': 'stop_movement',\r\n            'message': f\"Pausing as I'm not sure about '{command}'\",\r\n            'strategy': 'execute_safe_default'\r\n        }\r\n\r\n    def handoff_to_human(self, command: str, context: Dict) -> Dict:\r\n        \"\"\"Hand off to human operator\"\"\"\r\n        return {\r\n            'action_type': 'handoff',\r\n            'message': f\"I cannot perform '{command}'. Connecting you with a human operator.\",\r\n            'strategy': 'handoff_to_human'\r\n        }\n"})}),"\n",(0,a.jsx)(n.h2,{id:"isaac-integration-for-language-to-action-mapping",children:"Isaac Integration for Language-to-Action Mapping"}),"\n",(0,a.jsx)(n.h3,{id:"ros-2-interface-for-action-mapping",children:"ROS 2 Interface for Action Mapping"}),"\n",(0,a.jsx)(n.p,{children:"Integrating language-to-action mapping with ROS 2 and Isaac systems:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String\r\nfrom geometry_msgs.msg import Pose, Point\r\nfrom action_msgs.msg import GoalStatus\r\nfrom rclpy.action import ActionServer, GoalResponse, CancelResponse\r\nfrom rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy\r\n\r\nclass IsaacLanguageActionMapperNode(Node):\r\n    def __init__(self):\r\n        super().__init__('isaac_language_action_mapper')\r\n\r\n        # Publishers\r\n        self.action_plan_publisher = self.create_publisher(String, 'action_plan', 10)\r\n        self.status_publisher = self.create_publisher(String, 'action_mapping_status', 10)\r\n\r\n        # Subscribers\r\n        self.language_command_subscriber = self.create_subscription(\r\n            String, 'natural_language_command', self.language_command_callback, 10\r\n        )\r\n\r\n        # Action server for complex command mapping\r\n        self.mapping_server = ActionServer(\r\n            self,\r\n            MapLanguageToAction,\r\n            'map_language_to_action',\r\n            self.map_language_to_action_callback,\r\n            goal_callback=self.goal_callback,\r\n            cancel_callback=self.cancel_callback\r\n        )\r\n\r\n        # Initialize components\r\n        self.hybrid_parser = HybridSemanticParser()\r\n        self.context_aware_mapper = ContextAwareActionMapper()\r\n        self.action_planner = ActionExecutionPlanner()\r\n        self.ambiguity_resolver = AmbiguityResolver()\r\n        self.fallback_manager = FallbackManager()\r\n\r\n        self.get_logger().info('Isaac Language-to-Action Mapper Node initialized')\r\n\r\n    def language_command_callback(self, msg):\r\n        \"\"\"Handle incoming natural language commands\"\"\"\r\n        try:\r\n            command = msg.data\r\n            self.get_logger().info(f'Received command: {command}')\r\n\r\n            # Get current context\r\n            context = self.get_current_context()\r\n\r\n            # Detect and resolve ambiguities\r\n            ambiguity_info = self.ambiguity_resolver.detect_ambiguity(command, context)\r\n\r\n            if ambiguity_info['detected']:\r\n                resolution = self.ambiguity_resolver.resolve_ambiguity(\r\n                    command, ambiguity_info, context\r\n                )\r\n\r\n                if resolution['clarification_needed']:\r\n                    # Publish clarification request\r\n                    clarification_msg = String()\r\n                    clarification_msg.data = resolution['request']\r\n                    self.status_publisher.publish(clarification_msg)\r\n                    return\r\n\r\n                command = resolution['command']\r\n\r\n            # Parse command\r\n            parsed_command = self.hybrid_parser.parse_command(command, context)\r\n\r\n            # Map to contextual action\r\n            action_mapping = self.context_aware_mapper.map_with_context(\r\n                parsed_command, context\r\n            )\r\n\r\n            # Check feasibility\r\n            if not action_mapping['feasibility']:\r\n                fallback_result = self.fallback_manager.handle_unmappable_command(\r\n                    command, context\r\n                )\r\n                self.handle_fallback_result(fallback_result)\r\n                return\r\n\r\n            # Plan execution\r\n            execution_plan = self.action_planner.plan_execution(action_mapping)\r\n\r\n            # Publish action plan\r\n            plan_msg = String()\r\n            plan_msg.data = str(execution_plan)\r\n            self.action_plan_publisher.publish(plan_msg)\r\n\r\n            self.get_logger().info(f'Mapped command to action plan: {execution_plan}')\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f'Error mapping command: {e}')\r\n            # Handle with fallback\r\n            fallback_result = self.fallback_manager.handle_unmappable_command(\r\n                msg.data, self.get_current_context()\r\n            )\r\n            self.handle_fallback_result(fallback_result)\r\n\r\n    def goal_callback(self, goal_request):\r\n        \"\"\"Handle mapping goal\"\"\"\r\n        self.get_logger().info(f'Received mapping goal: {goal_request.command}')\r\n        return GoalResponse.ACCEPT\r\n\r\n    def cancel_callback(self, goal_handle):\r\n        \"\"\"Handle mapping cancellation\"\"\"\r\n        self.get_logger().info('Mapping cancelled')\r\n        return CancelResponse.ACCEPT\r\n\r\n    def map_language_to_action_callback(self, goal_handle):\r\n        \"\"\"Map language to action as action server\"\"\"\r\n        feedback_msg = MapLanguageToAction.Feedback()\r\n        result_msg = MapLanguageToAction.Result()\r\n\r\n        try:\r\n            command = goal_handle.request.command\r\n            self.get_logger().info(f'Mapping command: {command}')\r\n\r\n            # Get context\r\n            context = self.get_current_context()\r\n\r\n            # Update feedback\r\n            feedback_msg.status = 'Parsing command'\r\n            goal_handle.publish_feedback(feedback_msg)\r\n\r\n            # Parse command\r\n            parsed_command = self.hybrid_parser.parse_command(command, context)\r\n\r\n            # Update feedback\r\n            feedback_msg.status = 'Resolving ambiguities'\r\n            goal_handle.publish_feedback(feedback_msg)\r\n\r\n            # Detect and resolve ambiguities\r\n            ambiguity_info = self.ambiguity_resolver.detect_ambiguity(command, context)\r\n            if ambiguity_info['detected']:\r\n                resolution = self.ambiguity_resolver.resolve_ambiguity(\r\n                    command, ambiguity_info, context\r\n                )\r\n\r\n                if resolution['clarification_needed']:\r\n                    result_msg.success = False\r\n                    result_msg.message = resolution['request']\r\n                    result_msg.requires_clarification = True\r\n                    goal_handle.succeed()\r\n                    return result_msg\r\n\r\n                # Use resolved command\r\n                resolved_command = resolution['command']\r\n                parsed_command = self.hybrid_parser.parse_command(resolved_command, context)\r\n\r\n            # Update feedback\r\n            feedback_msg.status = 'Mapping to action'\r\n            goal_handle.publish_feedback(feedback_msg)\r\n\r\n            # Map to action\r\n            action_mapping = self.context_aware_mapper.map_with_context(\r\n                parsed_command, context\r\n            )\r\n\r\n            # Check feasibility\r\n            if not action_mapping['feasibility']:\r\n                fallback_result = self.fallback_manager.handle_unmappable_command(\r\n                    command, context\r\n                )\r\n                result_msg.success = False\r\n                result_msg.message = fallback_result['message']\r\n                goal_handle.abort()\r\n                return result_msg\r\n\r\n            # Plan execution\r\n            execution_plan = self.action_planner.plan_execution(action_mapping)\r\n\r\n            # Update feedback\r\n            feedback_msg.status = 'Planning complete'\r\n            goal_handle.publish_feedback(feedback_msg)\r\n\r\n            # Set result\r\n            result_msg.success = True\r\n            result_msg.message = f'Successfully mapped command to action plan'\r\n            result_msg.action_plan = str(execution_plan)\r\n            result_msg.action_mapping = str(action_mapping)\r\n\r\n            goal_handle.succeed()\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f'Mapping failed: {e}')\r\n            result_msg.success = False\r\n            result_msg.message = f'Mapping failed: {str(e)}'\r\n            goal_handle.abort()\r\n\r\n        return result_msg\r\n\r\n    def get_current_context(self):\r\n        \"\"\"Get current system context\"\"\"\r\n        # This would integrate with perception, mapping, and other systems\r\n        return {\r\n            'objects': self.get_detected_objects(),\r\n            'robot_pose': self.get_robot_pose(),\r\n            'named_locations': self.get_known_locations(),\r\n            'robot_capabilities': self.get_robot_capabilities(),\r\n            'available_actions': self.get_available_actions(),\r\n            'recent_objects': self.get_recent_objects()\r\n        }\r\n\r\n    def get_detected_objects(self):\r\n        \"\"\"Get currently detected objects\"\"\"\r\n        # Implementation would interface with perception system\r\n        return []\r\n\r\n    def get_robot_pose(self):\r\n        \"\"\"Get current robot pose\"\"\"\r\n        # Implementation would interface with localization system\r\n        return [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\r\n\r\n    def get_known_locations(self):\r\n        \"\"\"Get known named locations\"\"\"\r\n        # Implementation would interface with mapping system\r\n        return {\r\n            'kitchen': [5.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0],\r\n            'living_room': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\r\n        }\r\n\r\n    def get_robot_capabilities(self):\r\n        \"\"\"Get robot capabilities\"\"\"\r\n        return ['navigation', 'manipulation', 'perception']\r\n\r\n    def get_available_actions(self):\r\n        \"\"\"Get available robot actions\"\"\"\r\n        return ['navigate_to', 'grasp_object', 'place_object', 'find_object']\r\n\r\n    def get_recent_objects(self):\r\n        \"\"\"Get recently referenced objects\"\"\"\r\n        return []\r\n\r\n    def handle_fallback_result(self, fallback_result):\r\n        \"\"\"Handle fallback result\"\"\"\r\n        if 'message' in fallback_result:\r\n            status_msg = String()\r\n            status_msg.data = fallback_result['message']\r\n            self.status_publisher.publish(status_msg)\r\n\r\nclass MapLanguageToAction:\r\n    def __init__(self):\r\n        self.command = \"\"\r\n\r\n    class Feedback:\r\n        def __init__(self):\r\n            self.status = \"\"\r\n\r\n    class Result:\r\n        def __init__(self):\r\n            self.success = False\r\n            self.message = \"\"\r\n            self.action_plan = \"\"\r\n            self.action_mapping = \"\"\r\n            self.requires_clarification = False\r\n\r\n# Action execution orchestrator\r\nclass ActionOrchestrator:\r\n    def __init__(self, node):\r\n        self.node = node\r\n        self.action_queue = []\r\n        self.is_executing = False\r\n\r\n    def queue_action_plan(self, action_plan: List[Dict], priority: int = 0):\r\n        \"\"\"Queue action plan for execution\"\"\"\r\n        plan_item = {\r\n            'plan': action_plan,\r\n            'priority': priority,\r\n            'timestamp': time.time(),\r\n            'status': 'queued'\r\n        }\r\n\r\n        # Insert based on priority\r\n        self.action_queue.append(plan_item)\r\n        self.action_queue.sort(key=lambda x: (-x['priority'], x['timestamp']))\r\n\r\n        # Start execution if not already running\r\n        if not self.is_executing:\r\n            self.execute_next_plan()\r\n\r\n    def execute_next_plan(self):\r\n        \"\"\"Execute the next action plan in the queue\"\"\"\r\n        if self.action_queue:\r\n            self.is_executing = True\r\n            next_plan = self.action_queue.pop(0)\r\n            next_plan['status'] = 'executing'\r\n\r\n            # Execute plan asynchronously\r\n            self.execute_action_plan(next_plan['plan'])\r\n\r\n    def execute_action_plan(self, plan: List[Dict]):\r\n        \"\"\"Execute action plan\"\"\"\r\n        for step in plan:\r\n            try:\r\n                result = self.execute_step(step)\r\n                if not result['success']:\r\n                    self.node.get_logger().error(f'Step failed: {step}')\r\n                    break\r\n            except Exception as e:\r\n                self.node.get_logger().error(f'Step execution error: {e}')\r\n                break\r\n\r\n        self.is_executing = False\r\n        if self.action_queue:\r\n            self.execute_next_plan()\r\n\r\n    def execute_step(self, step: Dict):\r\n        \"\"\"Execute individual step\"\"\"\r\n        # This would interface with appropriate execution systems\r\n        # For now, simulate execution\r\n        import time\r\n        time.sleep(0.1)  # Simulate execution time\r\n\r\n        return {'success': True, 'result': 'completed'}\n"})}),"\n",(0,a.jsx)(n.h2,{id:"evaluation-and-validation",children:"Evaluation and Validation"}),"\n",(0,a.jsx)(n.h3,{id:"language-to-action-mapping-evaluation",children:"Language-to-Action Mapping Evaluation"}),"\n",(0,a.jsx)(n.p,{children:"Evaluating language-to-action mapping systems requires comprehensive benchmarks:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"class LanguageActionMappingEvaluator:\r\n    def __init__(self, mapper_system):\r\n        self.mapper_system = mapper_system\r\n        self.results_log = []\r\n\r\n    def evaluate_mapping_accuracy(self, test_cases):\r\n        \"\"\"Evaluate accuracy of language-to-action mapping\"\"\"\r\n        correct_mappings = 0\r\n        total_cases = len(test_cases)\r\n\r\n        for test_case in test_cases:\r\n            command = test_case['command']\r\n            expected_action = test_case['expected_action']\r\n            context = test_case.get('context', {})\r\n\r\n            try:\r\n                # Map command to action\r\n                parsed = self.mapper_system.hybrid_parser.parse_command(command, context)\r\n                mapped = self.mapper_system.context_aware_mapper.map_with_context(parsed, context)\r\n\r\n                # Check if mapping is correct\r\n                if self.actions_match(mapped, expected_action):\r\n                    correct_mappings += 1\r\n            except Exception as e:\r\n                print(f\"Mapping error for '{command}': {e}\")\r\n\r\n        accuracy = correct_mappings / total_cases if total_cases > 0 else 0.0\r\n        return accuracy\r\n\r\n    def evaluate_ambiguity_resolution(self, ambiguous_cases):\r\n        \"\"\"Evaluate ambiguity resolution effectiveness\"\"\"\r\n        correctly_resolved = 0\r\n        total_ambiguous = len(ambiguous_cases)\r\n\r\n        for case in ambiguous_cases:\r\n            command = case['command']\r\n            expected_resolution = case['expected_resolution']\r\n            context = case.get('context', {})\r\n\r\n            try:\r\n                ambiguity_info = self.mapper_system.ambiguity_resolver.detect_ambiguity(\r\n                    command, context\r\n                )\r\n\r\n                if ambiguity_info['detected']:\r\n                    resolution = self.mapper_system.ambiguity_resolver.resolve_ambiguity(\r\n                        command, ambiguity_info, context\r\n                    )\r\n\r\n                    if self.resolutions_match(resolution, expected_resolution):\r\n                        correctly_resolved += 1\r\n            except Exception:\r\n                pass\r\n\r\n        resolution_rate = correctly_resolved / total_ambiguous if total_ambiguous > 0 else 0.0\r\n        return resolution_rate\r\n\r\n    def evaluate_fallback_effectiveness(self, unmappable_cases):\r\n        \"\"\"Evaluate effectiveness of fallback strategies\"\"\"\r\n        effective_fallbacks = 0\r\n        total_unmappable = len(unmappable_cases)\r\n\r\n        for case in unmappable_cases:\r\n            command = case['command']\r\n            context = case.get('context', {})\r\n\r\n            try:\r\n                fallback_result = self.mapper_system.fallback_manager.handle_unmappable_command(\r\n                    command, context\r\n                )\r\n\r\n                # Check if fallback was appropriate and helpful\r\n                if self.is_appropriate_fallback(fallback_result, case):\r\n                    effective_fallbacks += 1\r\n            except Exception:\r\n                pass\r\n\r\n        effectiveness = effective_fallbacks / total_unmappable if total_unmappable > 0 else 0.0\r\n        return effectiveness\r\n\r\n    def evaluate_execution_success(self, mapped_actions):\r\n        \"\"\"Evaluate success of executing mapped actions\"\"\"\r\n        successful_executions = 0\r\n        total_actions = len(mapped_actions)\r\n\r\n        for action in mapped_actions:\r\n            try:\r\n                # Plan execution\r\n                execution_plan = self.mapper_system.action_planner.plan_execution(action)\r\n\r\n                # Simulate execution (in real system, would execute on robot)\r\n                execution_result = self.simulate_execution(execution_plan)\r\n\r\n                if execution_result['success']:\r\n                    successful_executions += 1\r\n            except Exception:\r\n                pass\r\n\r\n        success_rate = successful_executions / total_actions if total_actions > 0 else 0.0\r\n        return success_rate\r\n\r\n    def run_comprehensive_evaluation(self, dataset):\r\n        \"\"\"Run comprehensive evaluation of mapping system\"\"\"\r\n        results = {}\r\n\r\n        # Mapping accuracy\r\n        mapping_tests = [case for case in dataset if 'mapping' in case.get('type', '')]\r\n        results['mapping_accuracy'] = self.evaluate_mapping_accuracy(mapping_tests)\r\n\r\n        # Ambiguity resolution\r\n        ambiguity_tests = [case for case in dataset if 'ambiguity' in case.get('type', '')]\r\n        results['ambiguity_resolution_rate'] = self.evaluate_ambiguity_resolution(ambiguity_tests)\r\n\r\n        # Fallback effectiveness\r\n        fallback_tests = [case for case in dataset if 'fallback' in case.get('type', '')]\r\n        results['fallback_effectiveness'] = self.evaluate_fallback_effectiveness(fallback_tests)\r\n\r\n        # Execution success\r\n        execution_tests = [case for case in dataset if 'execution' in case.get('type', '')]\r\n        results['execution_success_rate'] = self.evaluate_execution_success(execution_tests)\r\n\r\n        # Overall system response time\r\n        results['average_response_time'] = self.measure_response_time(dataset)\r\n\r\n        return results\r\n\r\n    def actions_match(self, mapped_action, expected_action):\r\n        \"\"\"Check if mapped action matches expected action\"\"\"\r\n        # Compare key aspects of the action\r\n        if mapped_action['action_type'] != expected_action.get('action_type'):\r\n            return False\r\n\r\n        # Check important parameters\r\n        expected_params = expected_action.get('parameters', {})\r\n        mapped_params = mapped_action.get('contextual_parameters', {})\r\n\r\n        for param, expected_value in expected_params.items():\r\n            if param not in mapped_params:\r\n                return False\r\n            if mapped_params[param] != expected_value:\r\n                return False\r\n\r\n        return True\r\n\r\n    def resolutions_match(self, resolution, expected_resolution):\r\n        \"\"\"Check if ambiguity resolution matches expected resolution\"\"\"\r\n        # Compare resolution results\r\n        return resolution.get('command') == expected_resolution.get('command')\r\n\r\n    def is_appropriate_fallback(self, fallback_result, test_case):\r\n        \"\"\"Check if fallback was appropriate for the case\"\"\"\r\n        # This would evaluate if the chosen fallback strategy was appropriate\r\n        return True  # Simplified for example\r\n\r\n    def simulate_execution(self, execution_plan):\r\n        \"\"\"Simulate action execution\"\"\"\r\n        # This would simulate the execution of the plan\r\n        # For now, return success for all plans\r\n        return {'success': True, 'steps_completed': len(execution_plan)}\r\n\r\n    def measure_response_time(self, dataset):\r\n        \"\"\"Measure average response time\"\"\"\r\n        times = []\r\n        for case in dataset:\r\n            command = case.get('command', '')\r\n            if command:\r\n                start_time = time.time()\r\n                try:\r\n                    # Simulate mapping process\r\n                    context = case.get('context', {})\r\n                    parsed = self.mapper_system.hybrid_parser.parse_command(command, context)\r\n                    mapped = self.mapper_system.context_aware_mapper.map_with_context(parsed, context)\r\n                    times.append(time.time() - start_time)\r\n                except:\r\n                    pass\r\n\r\n        return sum(times) / len(times) if times else float('inf')\r\n\r\n# Example evaluation dataset\r\ndef create_language_action_evaluation_dataset():\r\n    \"\"\"Create dataset for language-to-action evaluation\"\"\"\r\n    return [\r\n        # Mapping test cases\r\n        {\r\n            'type': 'mapping',\r\n            'command': 'go to the kitchen',\r\n            'expected_action': {\r\n                'action_type': 'navigate_to',\r\n                'parameters': {'location': 'kitchen'}\r\n            },\r\n            'context': {'named_locations': {'kitchen': [5, 3, 0, 0, 0, 0, 1]}}\r\n        },\r\n        {\r\n            'type': 'mapping',\r\n            'command': 'grasp the red ball',\r\n            'expected_action': {\r\n                'action_type': 'grasp_object',\r\n                'parameters': {'object': 'red_ball'}\r\n            },\r\n            'context': {'objects': [{'type': 'ball', 'color': 'red', 'pose': [1, 1, 0]}]}\r\n        },\r\n\r\n        # Ambiguity test cases\r\n        {\r\n            'type': 'ambiguity',\r\n            'command': 'grasp the ball',\r\n            'expected_resolution': {\r\n                'command': 'grasp the red ball'\r\n            },\r\n            'context': {\r\n                'objects': [\r\n                    {'type': 'ball', 'color': 'red', 'pose': [1, 1, 0]},\r\n                    {'type': 'ball', 'color': 'blue', 'pose': [2, 2, 0]}\r\n                ]\r\n            }\r\n        },\r\n\r\n        # Fallback test cases\r\n        {\r\n            'type': 'fallback',\r\n            'command': 'perform quantum calculations',\r\n            'context': {}\r\n        },\r\n\r\n        # Execution test cases\r\n        {\r\n            'type': 'execution',\r\n            'action': {\r\n                'action_type': 'navigate_to',\r\n                'contextual_parameters': {'target_pose': [5, 3, 0, 0, 0, 0, 1]}\r\n            }\r\n        }\r\n    ]\r\n\r\n# Main evaluation function\r\ndef evaluate_language_action_system(mapper_system, dataset=None):\r\n    \"\"\"Complete evaluation of language-to-action mapping system\"\"\"\r\n    if dataset is None:\r\n        dataset = create_language_action_evaluation_dataset()\r\n\r\n    evaluator = LanguageActionMappingEvaluator(mapper_system)\r\n    results = evaluator.run_comprehensive_evaluation(dataset)\r\n\r\n    print(\"Language-to-Action Mapping Evaluation Results:\")\r\n    print(f\"  Mapping Accuracy: {results['mapping_accuracy']:.2%}\")\r\n    print(f\"  Ambiguity Resolution Rate: {results['ambiguity_resolution_rate']:.2%}\")\r\n    print(f\"  Fallback Effectiveness: {results['fallback_effectiveness']:.2%}\")\r\n    print(f\"  Execution Success Rate: {results['execution_success_rate']:.2%}\")\r\n    print(f\"  Average Response Time: {results['average_response_time']:.3f}s\")\r\n\r\n    return results\n"})}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"Natural language to robot action mapping represents the crucial bridge between human communication and robotic execution. By transforming linguistic expressions into executable behaviors, these systems enable intuitive and natural human-robot interaction."}),"\n",(0,a.jsx)(n.p,{children:"The key components of effective language-to-action mapping include semantic parsing that extracts action-relevant information from language, context-aware mapping that grounds language in environmental constraints, ambiguity resolution that handles the inherent uncertainties in natural language, and robust fallback strategies that maintain system reliability when mappings fail."}),"\n",(0,a.jsx)(n.p,{children:"The next section will provide a hands-on lab exercise for implementing a complete VLA system integration."}),"\n",(0,a.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,a.jsx)(n.p,{children:"[All sources will be cited in the References section at the end of the book, following APA format]"})]})}function _(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}},8453(e,n,r){r.d(n,{R:()=>i,x:()=>s});var t=r(6540);const a={},o=t.createContext(a);function i(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);